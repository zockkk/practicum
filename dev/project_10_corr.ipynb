{"cells":[{"cell_type":"markdown","metadata":{},"source":["\n","Привет очередной раз, меня зовут Люман Аблаев. Сегодня я проверю твой проект.\n","<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n","<br> Желательно реагировать на красные комментарии ('исправил', 'не понятно как исправить ошибку', ...)\n","<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n","\n","Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Успех:</b> Если все сделано отлично\n","</div>\n","\n","<div class=\"alert alert-block alert-info\">\n","<b>Совет: </b> Если можно немного улучшить\n","</div>\n","\n","<div class=\"alert alert-block alert-danger\">\n","<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n","</div>\n","\n","-------------------\n","\n","Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n","<div class=\"alert alert-block alert-warning\">\n","<b>Комментарий студента:</b> ...\n","</div>\n","\n","<div class=\"alert alert-block alert-warning\">\n","<b>Изменения:</b> Были внесены следующие изменения ...\n","</div>\n","\n","\n","\n","\n","\n","\n","\n","<font color='orange' style='font-size:24px; font-weight:bold'>Общее впечатление</font>\n","* Приятно было снова проверять твою работу\n","- Я постарался оставить полезные советы, надеюсь они тебе пригодятся.\n","- Увы, я обнаружил небольшие недочеты  в работе, но я думаю  у тебя не займет много усилий их исправить.\n","- Давай еще разок"]},{"cell_type":"markdown","metadata":{},"source":["# Модель для сервиса по продаже авто"]},{"cell_type":"markdown","metadata":{},"source":["## Описание проекта"]},{"cell_type":"markdown","metadata":{},"source":["### Описание данных"]},{"cell_type":"markdown","metadata":{},"source":["* Сервис по продаже автомобилей с пропегом разрабатывает приложение для привлечения клиентов. В нем можно будет узнать рыночную стоимость своего автомобиля.\n","* Необходимо постоить модель, которая умеет определять рыночную стоимость автомобиля.\n","* Даны данные о технических характеристиках, комплектующих и ценах других автомобилей.\n","* Важные критерии:\n","    * качество предсказания;\n","    * время обучения модели;\n","    * время предсказания модели."]},{"cell_type":"markdown","metadata":{},"source":["### План"]},{"cell_type":"markdown","metadata":{},"source":["* Загрузка и предобработка данных.\n","* Обработка аномалий.\n","* Подготовка выборки к обучению моделей.\n","* Обучение разных моделей.\n","* Анализ времени предсказаний, времени обучения и качества моделей.\n","* Выбор лучшей модели.  "]},{"cell_type":"markdown","metadata":{},"source":["## Инициализация библиотек и констант"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import BaggingRegressor\n","from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n","from sklearn.metrics import root_mean_squared_error\n","from sklearn.dummy import DummyRegressor\n","from lightgbm import LGBMRegressor\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n","from sklearn.compose import make_column_transformer\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["RANDOM_STATE = 12345"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div class=\"alert alert-block alert-success\">\n","<b>Успех:</b> Импорты  как всегда на месте\n","</div>\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Загрузка и предобработка данных"]},{"cell_type":"markdown","metadata":{},"source":["### Загрузка и изучение данных"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["try:\n","    data = pd.read_csv('../../datasets/autos.csv')\n","except:\n","    data = pd.read_csv('https://code.s3.yandex.net/datasets/autos.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DateCrawled</th>\n","      <th>Price</th>\n","      <th>VehicleType</th>\n","      <th>RegistrationYear</th>\n","      <th>Gearbox</th>\n","      <th>Power</th>\n","      <th>Model</th>\n","      <th>Kilometer</th>\n","      <th>RegistrationMonth</th>\n","      <th>FuelType</th>\n","      <th>Brand</th>\n","      <th>Repaired</th>\n","      <th>DateCreated</th>\n","      <th>NumberOfPictures</th>\n","      <th>PostalCode</th>\n","      <th>LastSeen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2016-03-24 11:52:17</td>\n","      <td>480</td>\n","      <td>NaN</td>\n","      <td>1993</td>\n","      <td>manual</td>\n","      <td>0</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>0</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>NaN</td>\n","      <td>2016-03-24 00:00:00</td>\n","      <td>0</td>\n","      <td>70435</td>\n","      <td>2016-04-07 03:16:57</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2016-03-24 10:58:45</td>\n","      <td>18300</td>\n","      <td>coupe</td>\n","      <td>2011</td>\n","      <td>manual</td>\n","      <td>190</td>\n","      <td>NaN</td>\n","      <td>125000</td>\n","      <td>5</td>\n","      <td>gasoline</td>\n","      <td>audi</td>\n","      <td>yes</td>\n","      <td>2016-03-24 00:00:00</td>\n","      <td>0</td>\n","      <td>66954</td>\n","      <td>2016-04-07 01:46:50</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2016-03-14 12:52:21</td>\n","      <td>9800</td>\n","      <td>suv</td>\n","      <td>2004</td>\n","      <td>auto</td>\n","      <td>163</td>\n","      <td>grand</td>\n","      <td>125000</td>\n","      <td>8</td>\n","      <td>gasoline</td>\n","      <td>jeep</td>\n","      <td>NaN</td>\n","      <td>2016-03-14 00:00:00</td>\n","      <td>0</td>\n","      <td>90480</td>\n","      <td>2016-04-05 12:47:46</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2016-03-17 16:54:04</td>\n","      <td>1500</td>\n","      <td>small</td>\n","      <td>2001</td>\n","      <td>manual</td>\n","      <td>75</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>6</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>no</td>\n","      <td>2016-03-17 00:00:00</td>\n","      <td>0</td>\n","      <td>91074</td>\n","      <td>2016-03-17 17:40:17</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2016-03-31 17:25:20</td>\n","      <td>3600</td>\n","      <td>small</td>\n","      <td>2008</td>\n","      <td>manual</td>\n","      <td>69</td>\n","      <td>fabia</td>\n","      <td>90000</td>\n","      <td>7</td>\n","      <td>gasoline</td>\n","      <td>skoda</td>\n","      <td>no</td>\n","      <td>2016-03-31 00:00:00</td>\n","      <td>0</td>\n","      <td>60437</td>\n","      <td>2016-04-06 10:17:21</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2016-04-04 17:36:23</td>\n","      <td>650</td>\n","      <td>sedan</td>\n","      <td>1995</td>\n","      <td>manual</td>\n","      <td>102</td>\n","      <td>3er</td>\n","      <td>150000</td>\n","      <td>10</td>\n","      <td>petrol</td>\n","      <td>bmw</td>\n","      <td>yes</td>\n","      <td>2016-04-04 00:00:00</td>\n","      <td>0</td>\n","      <td>33775</td>\n","      <td>2016-04-06 19:17:07</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2016-04-01 20:48:51</td>\n","      <td>2200</td>\n","      <td>convertible</td>\n","      <td>2004</td>\n","      <td>manual</td>\n","      <td>109</td>\n","      <td>2_reihe</td>\n","      <td>150000</td>\n","      <td>8</td>\n","      <td>petrol</td>\n","      <td>peugeot</td>\n","      <td>no</td>\n","      <td>2016-04-01 00:00:00</td>\n","      <td>0</td>\n","      <td>67112</td>\n","      <td>2016-04-05 18:18:39</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2016-03-21 18:54:38</td>\n","      <td>0</td>\n","      <td>sedan</td>\n","      <td>1980</td>\n","      <td>manual</td>\n","      <td>50</td>\n","      <td>other</td>\n","      <td>40000</td>\n","      <td>7</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>no</td>\n","      <td>2016-03-21 00:00:00</td>\n","      <td>0</td>\n","      <td>19348</td>\n","      <td>2016-03-25 16:47:58</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2016-04-04 23:42:13</td>\n","      <td>14500</td>\n","      <td>bus</td>\n","      <td>2014</td>\n","      <td>manual</td>\n","      <td>125</td>\n","      <td>c_max</td>\n","      <td>30000</td>\n","      <td>8</td>\n","      <td>petrol</td>\n","      <td>ford</td>\n","      <td>NaN</td>\n","      <td>2016-04-04 00:00:00</td>\n","      <td>0</td>\n","      <td>94505</td>\n","      <td>2016-04-04 23:42:13</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2016-03-17 10:53:50</td>\n","      <td>999</td>\n","      <td>small</td>\n","      <td>1998</td>\n","      <td>manual</td>\n","      <td>101</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>volkswagen</td>\n","      <td>NaN</td>\n","      <td>2016-03-17 00:00:00</td>\n","      <td>0</td>\n","      <td>27472</td>\n","      <td>2016-03-31 17:17:06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           DateCrawled  Price  VehicleType  RegistrationYear Gearbox  Power  \\\n","0  2016-03-24 11:52:17    480          NaN              1993  manual      0   \n","1  2016-03-24 10:58:45  18300        coupe              2011  manual    190   \n","2  2016-03-14 12:52:21   9800          suv              2004    auto    163   \n","3  2016-03-17 16:54:04   1500        small              2001  manual     75   \n","4  2016-03-31 17:25:20   3600        small              2008  manual     69   \n","5  2016-04-04 17:36:23    650        sedan              1995  manual    102   \n","6  2016-04-01 20:48:51   2200  convertible              2004  manual    109   \n","7  2016-03-21 18:54:38      0        sedan              1980  manual     50   \n","8  2016-04-04 23:42:13  14500          bus              2014  manual    125   \n","9  2016-03-17 10:53:50    999        small              1998  manual    101   \n","\n","     Model  Kilometer  RegistrationMonth  FuelType       Brand Repaired  \\\n","0     golf     150000                  0    petrol  volkswagen      NaN   \n","1      NaN     125000                  5  gasoline        audi      yes   \n","2    grand     125000                  8  gasoline        jeep      NaN   \n","3     golf     150000                  6    petrol  volkswagen       no   \n","4    fabia      90000                  7  gasoline       skoda       no   \n","5      3er     150000                 10    petrol         bmw      yes   \n","6  2_reihe     150000                  8    petrol     peugeot       no   \n","7    other      40000                  7    petrol  volkswagen       no   \n","8    c_max      30000                  8    petrol        ford      NaN   \n","9     golf     150000                  0       NaN  volkswagen      NaN   \n","\n","           DateCreated  NumberOfPictures  PostalCode             LastSeen  \n","0  2016-03-24 00:00:00                 0       70435  2016-04-07 03:16:57  \n","1  2016-03-24 00:00:00                 0       66954  2016-04-07 01:46:50  \n","2  2016-03-14 00:00:00                 0       90480  2016-04-05 12:47:46  \n","3  2016-03-17 00:00:00                 0       91074  2016-03-17 17:40:17  \n","4  2016-03-31 00:00:00                 0       60437  2016-04-06 10:17:21  \n","5  2016-04-04 00:00:00                 0       33775  2016-04-06 19:17:07  \n","6  2016-04-01 00:00:00                 0       67112  2016-04-05 18:18:39  \n","7  2016-03-21 00:00:00                 0       19348  2016-03-25 16:47:58  \n","8  2016-04-04 00:00:00                 0       94505  2016-04-04 23:42:13  \n","9  2016-03-17 00:00:00                 0       27472  2016-03-31 17:17:06  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["* DateCrawled — дата скачивания анкеты из базы\n","* VehicleType — тип автомобильного кузова\n","* RegistrationYear — год регистрации автомобиля\n","* Gearbox — тип коробки передач\n","* Power — мощность (л. с.)\n","* Model — модель автомобиля\n","* Kilometer — пробег (км)\n","* RegistrationMonth — месяц регистрации автомобиля\n","* FuelType — тип топлива\n","* Brand — марка автомобиля\n","* Repaired — была машина в ремонте или нет\n","* DateCreated — дата создания анкеты\n","* NumberOfPictures — количество фотографий автомобиля\n","* PostalCode — почтовый индекс владельца анкеты (пользователя)\n","* LastSeen — дата последней активности пользователя\n","* Price - цена автомобиля"]},{"cell_type":"markdown","metadata":{},"source":["Не все колонки являются нужными для подсчета стоимости автомобиля. Нужно удалить колонки: DateCrawled, DateCreated, NumberOfPictures, PostalCode, LastSeen, RegistrationMonth."]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["data = data.drop(['DateCrawled', 'DateCreated', 'NumberOfPictures', 'PostalCode', 'LastSeen', 'RegistrationMonth'], axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Успех:</b> Удалить неинформативные признаки - верное решение\n","</div>"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 354369 entries, 0 to 354368\n","Data columns (total 10 columns):\n"," #   Column            Non-Null Count   Dtype \n","---  ------            --------------   ----- \n"," 0   Price             354369 non-null  int64 \n"," 1   VehicleType       316879 non-null  object\n"," 2   RegistrationYear  354369 non-null  int64 \n"," 3   Gearbox           334536 non-null  object\n"," 4   Power             354369 non-null  int64 \n"," 5   Model             334664 non-null  object\n"," 6   Kilometer         354369 non-null  int64 \n"," 7   FuelType          321474 non-null  object\n"," 8   Brand             354369 non-null  object\n"," 9   Repaired          283215 non-null  object\n","dtypes: int64(4), object(6)\n","memory usage: 27.0+ MB\n"]}],"source":["data.info()"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Price</th>\n","      <th>RegistrationYear</th>\n","      <th>Power</th>\n","      <th>Kilometer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>354369.000000</td>\n","      <td>354369.000000</td>\n","      <td>354369.000000</td>\n","      <td>354369.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>4416.656776</td>\n","      <td>2004.234448</td>\n","      <td>110.094337</td>\n","      <td>128211.172535</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>4514.158514</td>\n","      <td>90.227958</td>\n","      <td>189.850405</td>\n","      <td>37905.341530</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>1000.000000</td>\n","      <td>0.000000</td>\n","      <td>5000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1050.000000</td>\n","      <td>1999.000000</td>\n","      <td>69.000000</td>\n","      <td>125000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2700.000000</td>\n","      <td>2003.000000</td>\n","      <td>105.000000</td>\n","      <td>150000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>6400.000000</td>\n","      <td>2008.000000</td>\n","      <td>143.000000</td>\n","      <td>150000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>20000.000000</td>\n","      <td>9999.000000</td>\n","      <td>20000.000000</td>\n","      <td>150000.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Price  RegistrationYear          Power      Kilometer\n","count  354369.000000     354369.000000  354369.000000  354369.000000\n","mean     4416.656776       2004.234448     110.094337  128211.172535\n","std      4514.158514         90.227958     189.850405   37905.341530\n","min         0.000000       1000.000000       0.000000    5000.000000\n","25%      1050.000000       1999.000000      69.000000  125000.000000\n","50%      2700.000000       2003.000000     105.000000  150000.000000\n","75%      6400.000000       2008.000000     143.000000  150000.000000\n","max     20000.000000       9999.000000   20000.000000  150000.000000"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data.describe()"]},{"cell_type":"markdown","metadata":{},"source":["### Анализ и предобработка данных"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 354369 entries, 0 to 354368\n","Data columns (total 10 columns):\n"," #   Column            Non-Null Count   Dtype \n","---  ------            --------------   ----- \n"," 0   Price             354369 non-null  int64 \n"," 1   VehicleType       316879 non-null  object\n"," 2   RegistrationYear  354369 non-null  int64 \n"," 3   Gearbox           334536 non-null  object\n"," 4   Power             354369 non-null  int64 \n"," 5   Model             334664 non-null  object\n"," 6   Kilometer         354369 non-null  int64 \n"," 7   FuelType          321474 non-null  object\n"," 8   Brand             354369 non-null  object\n"," 9   Repaired          283215 non-null  object\n","dtypes: int64(4), object(6)\n","memory usage: 27.0+ MB\n"]}],"source":["data.info()"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Price</th>\n","      <th>VehicleType</th>\n","      <th>RegistrationYear</th>\n","      <th>Gearbox</th>\n","      <th>Power</th>\n","      <th>Model</th>\n","      <th>Kilometer</th>\n","      <th>FuelType</th>\n","      <th>Brand</th>\n","      <th>Repaired</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>480</td>\n","      <td>NaN</td>\n","      <td>1993</td>\n","      <td>manual</td>\n","      <td>0</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>18300</td>\n","      <td>coupe</td>\n","      <td>2011</td>\n","      <td>manual</td>\n","      <td>190</td>\n","      <td>NaN</td>\n","      <td>125000</td>\n","      <td>gasoline</td>\n","      <td>audi</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9800</td>\n","      <td>suv</td>\n","      <td>2004</td>\n","      <td>auto</td>\n","      <td>163</td>\n","      <td>grand</td>\n","      <td>125000</td>\n","      <td>gasoline</td>\n","      <td>jeep</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Price VehicleType  RegistrationYear Gearbox  Power  Model  Kilometer  \\\n","0    480         NaN              1993  manual      0   golf     150000   \n","1  18300       coupe              2011  manual    190    NaN     125000   \n","2   9800         suv              2004    auto    163  grand     125000   \n","\n","   FuelType       Brand Repaired  \n","0    petrol  volkswagen      NaN  \n","1  gasoline        audi      yes  \n","2  gasoline        jeep      NaN  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data.head(3)"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["45040"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data.duplicated().sum()"]},{"cell_type":"markdown","metadata":{},"source":["Дублакаты удалять не будем, возможно это разные машины с одинаковыми признаками."]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["data.columns = ['price', 'vehicle_type', 'registration_year', 'gearbox', 'power', 'model', 'kilometer', 'fuel_type', 'brand', 'repaired']"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["gearbox\n","manual    268251\n","auto       66285\n","Name: count, dtype: int64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["data['gearbox'].value_counts()"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["repaired\n","no     247161\n","yes     36054\n","Name: count, dtype: int64"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["data['repaired'].value_counts()"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>price</th>\n","      <th>registration_year</th>\n","      <th>power</th>\n","      <th>kilometer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>price</th>\n","      <td>1.000000</td>\n","      <td>0.026916</td>\n","      <td>0.158872</td>\n","      <td>-0.333199</td>\n","    </tr>\n","    <tr>\n","      <th>registration_year</th>\n","      <td>0.026916</td>\n","      <td>1.000000</td>\n","      <td>-0.000828</td>\n","      <td>-0.053447</td>\n","    </tr>\n","    <tr>\n","      <th>power</th>\n","      <td>0.158872</td>\n","      <td>-0.000828</td>\n","      <td>1.000000</td>\n","      <td>0.024002</td>\n","    </tr>\n","    <tr>\n","      <th>kilometer</th>\n","      <td>-0.333199</td>\n","      <td>-0.053447</td>\n","      <td>0.024002</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      price  registration_year     power  kilometer\n","price              1.000000           0.026916  0.158872  -0.333199\n","registration_year  0.026916           1.000000 -0.000828  -0.053447\n","power              0.158872          -0.000828  1.000000   0.024002\n","kilometer         -0.333199          -0.053447  0.024002   1.000000"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["data[['price', 'registration_year', 'power', 'kilometer']].corr()"]},{"cell_type":"markdown","metadata":{},"source":["#### Обработка аномалий"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAlUAAAGdCAYAAAA7VYb2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4p0lEQVR4nO3df1xW9f3/8SeI/PDHBf4CZJK6NH+ky9SGmLo5+YBFLdN9UqM0Y9oPaCr5i2XqWptl09RpsrZKWzp/fJbONCkS01KGipI/SvyRhaYXuilcigkI5/tHX45eYYX4Vrjkcb/dzu2267xf1zmv8+4gz53rXAcvy7IsAQAA4Kp4V3cDAAAANwJCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGCAT3U3UJuUlZXp2LFjatiwoby8vKq7HQAAUAmWZenMmTMKCwuTt/d3X48iVF1Hx44dU3h4eHW3AQAAquDIkSNq0aLFd44Tqq6jhg0bSvrmP4rD4ajmbgAAQGW4XC6Fh4fbv8e/C6HqOir/yM/hcBCqAADwMD906w43qgMAABhAqAIAADCAUAUAAGBAtYaqTZs26d5771VYWJi8vLy0atUqe6ykpEQTJ05U586dVb9+fYWFhWnYsGE6duyY2zZOnTqluLg4ORwOBQUFKT4+XmfPnnWr2bVrl3r37i1/f3+Fh4drxowZFXpZsWKF2rdvL39/f3Xu3Fnvvvuu27hlWZoyZYqaN2+ugIAARUVF6cCBA+YmAwAAeLRqDVWFhYW67bbbNH/+/Apj586d044dO/Tss89qx44devvtt5WTk6Nf/vKXbnVxcXHau3ev0tLStGbNGm3atEmjRo2yx10ul6Kjo9WyZUtlZWXppZde0rRp0/Tqq6/aNVu2bNHQoUMVHx+vnTt3asCAARowYID27Nlj18yYMUNz585VSkqKMjMzVb9+fcXExOj8+fPXYGYAAIDHsWoISdbKlSu/t2br1q2WJOvLL7+0LMuyPv30U0uStW3bNrtm3bp1lpeXl/XVV19ZlmVZr7zyitWoUSOrqKjIrpk4caLVrl07+/UDDzxgxcbGuu0rIiLCeuyxxyzLsqyysjIrNDTUeumll+zx/Px8y8/Pz/rHP/5R6WMsKCiwJFkFBQWVfg8AAKhelf397VH3VBUUFMjLy0tBQUGSpIyMDAUFBal79+52TVRUlLy9vZWZmWnX9OnTR76+vnZNTEyMcnJydPr0absmKirKbV8xMTHKyMiQJB0+fFhOp9OtJjAwUBEREXbN5RQVFcnlcrktAADgxuQxoer8+fOaOHGihg4daj/jyel0Kjg42K3Ox8dHjRs3ltPptGtCQkLcaspf/1DNpeOXvu9yNZczffp0BQYG2gtPUwcA4MblEaGqpKREDzzwgCzL0oIFC6q7nUpLTk5WQUGBvRw5cqS6WwIAANdIjX+ienmg+vLLL5Wenu72JPLQ0FCdOHHCrf7ChQs6deqUQkND7Zq8vDy3mvLXP1Rz6Xj5uubNm7vVdOnS5Tt79/Pzk5+f35UcLgAA8FA1+kpVeaA6cOCAPvjgAzVp0sRtPDIyUvn5+crKyrLXpaenq6ysTBEREXbNpk2bVFJSYtekpaWpXbt2atSokV2zfv16t22npaUpMjJSktS6dWuFhoa61bhcLmVmZto1AACgdqvWUHX27FllZ2crOztb0jc3hGdnZys3N1clJSX61a9+pe3bt2vx4sUqLS2V0+mU0+lUcXGxJKlDhw7q37+/Ro4cqa1bt2rz5s1KTEzUkCFDFBYWJkl68MEH5evrq/j4eO3du1fLli3TnDlzlJSUZPcxevRopaamaubMmdq3b5+mTZum7du3KzExUdI3f+tnzJgxev7557V69Wrt3r1bw4YNU1hYmAYMGHBd5wwAANRQ1+fLiJe3YcMGS1KFZfjw4dbhw4cvOybJ2rBhg72N//73v9bQoUOtBg0aWA6HwxoxYoR15swZt/188sknVq9evSw/Pz/rRz/6kfXCCy9U6GX58uXWLbfcYvn6+lq33nqrtXbtWrfxsrIy69lnn7VCQkIsPz8/q1+/flZOTs4VHS+PVAAAwPNU9ve3l2VZVrWkuVrI5XIpMDBQBQUFbveGAQCAmquyv79r/I3qAABURatJa6u7he/1xQux1d0CDKvRN6oDAAB4CkIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAG+FR3AwAAz9Nq0trqbgGocbhSBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAHVGqo2bdqke++9V2FhYfLy8tKqVavcxi3L0pQpU9S8eXMFBAQoKipKBw4ccKs5deqU4uLi5HA4FBQUpPj4eJ09e9atZteuXerdu7f8/f0VHh6uGTNmVOhlxYoVat++vfz9/dW5c2e9++67V9wLAACovao1VBUWFuq2227T/PnzLzs+Y8YMzZ07VykpKcrMzFT9+vUVExOj8+fP2zVxcXHau3ev0tLStGbNGm3atEmjRo2yx10ul6Kjo9WyZUtlZWXppZde0rRp0/Tqq6/aNVu2bNHQoUMVHx+vnTt3asCAARowYID27NlzRb0AAIDay8uyLKu6m5AkLy8vrVy5UgMGDJD0zZWhsLAwPf300xo3bpwkqaCgQCEhIVq4cKGGDBmizz77TB07dtS2bdvUvXt3SVJqaqruvvtuHT16VGFhYVqwYIGeeeYZOZ1O+fr6SpImTZqkVatWad++fZKkwYMHq7CwUGvWrLH76dGjh7p06aKUlJRK9VIZLpdLgYGBKigokMPhMDJvAFAdWk1aW90teLwvXoit7hZQSZX9/V1j76k6fPiwnE6noqKi7HWBgYGKiIhQRkaGJCkjI0NBQUF2oJKkqKgoeXt7KzMz067p06ePHagkKSYmRjk5OTp9+rRdc+l+ymvK91OZXi6nqKhILpfLbQEAADemGhuqnE6nJCkkJMRtfUhIiD3mdDoVHBzsNu7j46PGjRu71VxuG5fu47tqLh3/oV4uZ/r06QoMDLSX8PDwHzhqAADgqWpsqLoRJCcnq6CgwF6OHDlS3S0BAIBrpMaGqtDQUElSXl6e2/q8vDx7LDQ0VCdOnHAbv3Dhgk6dOuVWc7ltXLqP76q5dPyHerkcPz8/ORwOtwUAANyYamyoat26tUJDQ7V+/Xp7ncvlUmZmpiIjIyVJkZGRys/PV1ZWll2Tnp6usrIyRURE2DWbNm1SSUmJXZOWlqZ27dqpUaNGds2l+ymvKd9PZXoBAAC1W7WGqrNnzyo7O1vZ2dmSvrkhPDs7W7m5ufLy8tKYMWP0/PPPa/Xq1dq9e7eGDRumsLAw+xuCHTp0UP/+/TVy5Eht3bpVmzdvVmJiooYMGaKwsDBJ0oMPPihfX1/Fx8dr7969WrZsmebMmaOkpCS7j9GjRys1NVUzZ87Uvn37NG3aNG3fvl2JiYmSVKleAABA7eZTnTvfvn27+vbta78uDzrDhw/XwoULNWHCBBUWFmrUqFHKz89Xr169lJqaKn9/f/s9ixcvVmJiovr16ydvb28NGjRIc+fOtccDAwP1/vvvKyEhQd26dVPTpk01ZcoUt2dZ9ezZU0uWLNHkyZP129/+Vm3bttWqVavUqVMnu6YyvQAAgNqrxjynqjbgOVUAbhQ8p+rq8Zwqz+Hxz6kCAADwJIQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAATU6VJWWlurZZ59V69atFRAQoJtvvlm///3vZVmWXWNZlqZMmaLmzZsrICBAUVFROnDggNt2Tp06pbi4ODkcDgUFBSk+Pl5nz551q9m1a5d69+4tf39/hYeHa8aMGRX6WbFihdq3by9/f3917txZ77777rU5cAAA4HFqdKh68cUXtWDBAs2bN0+fffaZXnzxRc2YMUN//vOf7ZoZM2Zo7ty5SklJUWZmpurXr6+YmBidP3/eromLi9PevXuVlpamNWvWaNOmTRo1apQ97nK5FB0drZYtWyorK0svvfSSpk2bpldffdWu2bJli4YOHar4+Hjt3LlTAwYM0IABA7Rnz57rMxkAAKBG87IuvexTw9xzzz0KCQnRa6+9Zq8bNGiQAgIC9NZbb8myLIWFhenpp5/WuHHjJEkFBQUKCQnRwoULNWTIEH322Wfq2LGjtm3bpu7du0uSUlNTdffdd+vo0aMKCwvTggUL9Mwzz8jpdMrX11eSNGnSJK1atUr79u2TJA0ePFiFhYVas2aN3UuPHj3UpUsXpaSkVOp4XC6XAgMDVVBQIIfDYWSOAKA6tJq0trpb8HhfvBBb3S2gkir7+7tGX6nq2bOn1q9fr/3790uSPvnkE3388ce66667JEmHDx+W0+lUVFSU/Z7AwEBFREQoIyNDkpSRkaGgoCA7UElSVFSUvL29lZmZadf06dPHDlSSFBMTo5ycHJ0+fdquuXQ/5TXl+7mcoqIiuVwutwUAANyYfKq7ge8zadIkuVwutW/fXnXq1FFpaan+8Ic/KC4uTpLkdDolSSEhIW7vCwkJscecTqeCg4Pdxn18fNS4cWO3mtatW1fYRvlYo0aN5HQ6v3c/lzN9+nT97ne/u9LDBgAAHqhGX6lavny5Fi9erCVLlmjHjh1atGiR/vSnP2nRokXV3VqlJCcnq6CgwF6OHDlS3S0BAIBrpEZfqRo/frwmTZqkIUOGSJI6d+6sL7/8UtOnT9fw4cMVGhoqScrLy1Pz5s3t9+Xl5alLly6SpNDQUJ04ccJtuxcuXNCpU6fs94eGhiovL8+tpvz1D9WUj1+On5+f/Pz8rvSwAQCAB6rRV6rOnTsnb2/3FuvUqaOysjJJUuvWrRUaGqr169fb4y6XS5mZmYqMjJQkRUZGKj8/X1lZWXZNenq6ysrKFBERYdds2rRJJSUldk1aWpratWunRo0a2TWX7qe8pnw/AACgdqvRoeree+/VH/7wB61du1ZffPGFVq5cqVmzZun++++XJHl5eWnMmDF6/vnntXr1au3evVvDhg1TWFiYBgwYIEnq0KGD+vfvr5EjR2rr1q3avHmzEhMTNWTIEIWFhUmSHnzwQfn6+io+Pl579+7VsmXLNGfOHCUlJdm9jB49WqmpqZo5c6b27dunadOmafv27UpMTLzu8wIAAGqeGv3x35///Gc9++yzevLJJ3XixAmFhYXpscce05QpU+yaCRMmqLCwUKNGjVJ+fr569eql1NRU+fv72zWLFy9WYmKi+vXrJ29vbw0aNEhz5861xwMDA/X+++8rISFB3bp1U9OmTTVlyhS3Z1n17NlTS5Ys0eTJk/Xb3/5Wbdu21apVq9SpU6frMxkAAKBGq9HPqbrR8JwqADcKnlN19XhOlee4IZ5TBQAA4CkIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAgCqFqs8//9x0HwAAAB6tSqGqTZs26tu3r9566y2dP3/edE8AAAAep0qhaseOHfrJT36ipKQkhYaG6rHHHtPWrVtN9wYAAOAxqhSqunTpojlz5ujYsWN6/fXXdfz4cfXq1UudOnXSrFmzdPLkSdN9AgAA1GhXdaO6j4+PBg4cqBUrVujFF1/UwYMHNW7cOIWHh2vYsGE6fvy4qT4BAABqtKsKVdu3b9eTTz6p5s2ba9asWRo3bpwOHTqktLQ0HTt2TPfdd5+pPgEAAGo0n6q8adasWXrjjTeUk5Oju+++W2+++abuvvtueXt/k9Fat26thQsXqlWrViZ7BQAAqLGqFKoWLFigRx99VI888oiaN29+2Zrg4GC99tprV9UcAACAp6hSqDpw4MAP1vj6+mr48OFV2TwAAIDHqdI9VW+88YZWrFhRYf2KFSu0aNGiq24KAADA01QpVE2fPl1NmzatsD44OFh//OMfr7opAAAAT1OlUJWbm6vWrVtXWN+yZUvl5uZedVMAAACepkqhKjg4WLt27aqw/pNPPlGTJk2uuikAAABPU6VQNXToUP3mN7/Rhg0bVFpaqtLSUqWnp2v06NEaMmSI6R4BAABqvCp9++/3v/+9vvjiC/Xr108+Pt9soqysTMOGDeOeKgAAUCtVKVT5+vpq2bJl+v3vf69PPvlEAQEB6ty5s1q2bGm6PwAAAI9QpVBV7pZbbtEtt9xiqhcAAACPVaVQVVpaqoULF2r9+vU6ceKEysrK3MbT09ONNAcAAOApqhSqRo8erYULFyo2NladOnWSl5eX6b4AAAA8SpVC1dKlS7V8+XLdfffdpvsBAADwSFV6pIKvr6/atGljuhcAAACPVaVQ9fTTT2vOnDmyLMt0PwAAAB6pSh//ffzxx9qwYYPWrVunW2+9VXXr1nUbf/vtt400BwAA4CmqFKqCgoJ0//33m+4FAADAY1UpVL3xxhum+wAAAPBoVbqnSpIuXLigDz74QH/5y1905swZSdKxY8d09uxZY80BAAB4iipdqfryyy/Vv39/5ebmqqioSP/zP/+jhg0b6sUXX1RRUZFSUlJM9wkAAFCjVelK1ejRo9W9e3edPn1aAQEB9vr7779f69evN9YcAACAp6jSlaqPPvpIW7Zska+vr9v6Vq1a6auvvjLSGAAAgCep0pWqsrIylZaWVlh/9OhRNWzY8KqbAgAA8DRVClXR0dGaPXu2/drLy0tnz57V1KlT+dM1AACgVqrSx38zZ85UTEyMOnbsqPPnz+vBBx/UgQMH1LRpU/3jH/8w3SMAAECN52VV8W/NXLhwQUuXLtWuXbt09uxZde3aVXFxcW43rsOdy+VSYGCgCgoK5HA4qrsdAKiyVpPWVncLuMa+eCG2uluoMSr7+7tKV6okycfHRw899FBV3w4AAHBDqdI9VW+++eb3LiZ99dVXeuihh9SkSRMFBASoc+fO2r59uz1uWZamTJmi5s2bKyAgQFFRUTpw4IDbNk6dOqW4uDg5HA4FBQUpPj6+wkNKd+3apd69e8vf31/h4eGaMWNGhV5WrFih9u3by9/fX507d9a7775r9FgBAIDnqtKVqtGjR7u9Likp0blz5+Tr66t69epp2LBhRpo7ffq07rzzTvXt21fr1q1Ts2bNdODAATVq1MiumTFjhubOnatFixapdevWevbZZxUTE6NPP/1U/v7+kqS4uDgdP35caWlpKikp0YgRIzRq1CgtWbJE0jeX9aKjoxUVFaWUlBTt3r1bjz76qIKCgjRq1ChJ0pYtWzR06FBNnz5d99xzj5YsWaIBAwZox44d6tSpk5HjBQAAnqvK91R924EDB/TEE09o/PjxiomJMbFJTZo0SZs3b9ZHH3102XHLshQWFqann35a48aNkyQVFBQoJCRECxcu1JAhQ/TZZ5+pY8eO2rZtm7p37y5JSk1N1d13362jR48qLCxMCxYs0DPPPCOn02k/e2vSpElatWqV9u3bJ0kaPHiwCgsLtWbNGnv/PXr0UJcuXSr9BHnuqQJwo+Ceqhsf91RdVNnf31X+23/f1rZtW73wwgsVrmJdjdWrV6t79+763//9XwUHB+v222/XX//6V3v88OHDcjqdioqKstcFBgYqIiJCGRkZkqSMjAwFBQXZgUqSoqKi5O3trczMTLumT58+bg8zjYmJUU5Ojk6fPm3XXLqf8pry/VxOUVGRXC6X2wIAAG5MxkKV9M3N68eOHTO2vc8//1wLFixQ27Zt9d577+mJJ57Qb37zGy1atEiS5HQ6JUkhISFu7wsJCbHHnE6ngoODK/TZuHFjt5rLbePSfXxXTfn45UyfPl2BgYH2Eh4efkXHDwAAPEeV7qlavXq122vLsnT8+HHNmzdPd955p5HGpG+e3N69e3f98Y9/lCTdfvvt2rNnj1JSUjR8+HBj+7lWkpOTlZSUZL92uVwEKwAAblBVClUDBgxwe+3l5aVmzZrpF7/4hWbOnGmiL0lS8+bN1bFjR7d1HTp00D//+U9JUmhoqCQpLy9PzZs3t2vy8vLUpUsXu+bEiRNu27hw4YJOnTplvz80NFR5eXluNeWvf6imfPxy/Pz85OfnV6ljBQAAnq3Kf/vv0qW0tFROp1NLlixxCzdX684771ROTo7buv3796tly5aSpNatWys0NFTr16+3x10ulzIzMxUZGSlJioyMVH5+vrKysuya9PR0lZWVKSIiwq7ZtGmTSkpK7Jq0tDS1a9fO/qZhZGSk237Ka8r3AwAAajej91SZNnbsWP373//WH//4Rx08eFBLlizRq6++qoSEBEnfXCEbM2aMnn/+ea1evVq7d+/WsGHDFBYWZl9N69Chg/r376+RI0dq69at2rx5sxITEzVkyBCFhYVJkh588EH5+voqPj5ee/fu1bJlyzRnzhy3j+5Gjx6t1NRUzZw5U/v27dO0adO0fft2JSYmXvd5AQAANU+VPv67NGz8kFmzZlVlF5KkO+64QytXrlRycrKee+45tW7dWrNnz1ZcXJxdM2HCBBUWFmrUqFHKz89Xr169lJqaaj+jSpIWL16sxMRE9evXT97e3ho0aJDmzp1rjwcGBur9999XQkKCunXrpqZNm2rKlCn2M6okqWfPnlqyZIkmT56s3/72t2rbtq1WrVrFM6oAAICkKj6nqm/fvtq5c6dKSkrUrl07Sd98LFenTh117dr14sa9vJSenm6uWw/Hc6oA3Ch4TtWNj+dUXXRN//bfvffeq4YNG2rRokX2PUenT5/WiBEj1Lt3bz399NNV6xoAAMBDVemeqpkzZ2r69Olufy6mUaNGev75541++w8AAMBTVClUuVwunTx5ssL6kydP6syZM1fdFAAAgKepUqi6//77NWLECL399ts6evSojh49qn/+85+Kj4/XwIEDTfcIAABQ41XpnqqUlBSNGzdODz74oP1sJx8fH8XHx+ull14y2iAAAIAnqFKoqlevnl555RW99NJLOnTokCTp5ptvVv369Y02BwAA4Cmu6uGfx48f1/Hjx9W2bVvVr19fVXg6AwAAwA2hSqHqv//9r/r166dbbrlFd999t44fPy5Jio+P53EKAACgVqpSqBo7dqzq1q2r3Nxc1atXz14/ePBgpaamGmsOAADAU1Tpnqr3339f7733nlq0aOG2vm3btvryyy+NNAYAAOBJqnSlqrCw0O0KVblTp07Jz8/vqpsCAADwNFUKVb1799abb75pv/by8lJZWZlmzJihvn37GmsOAADAU1Tp478ZM2aoX79+2r59u4qLizVhwgTt3btXp06d0ubNm033CAAAUONV6UpVp06dtH//fvXq1Uv33XefCgsLNXDgQO3cuVM333yz6R4BAABqvCu+UlVSUqL+/fsrJSVFzzzzzLXoCQAAwONc8ZWqunXrateuXdeiFwAAAI9VpY//HnroIb322mumewEAAPBYVbpR/cKFC3r99df1wQcfqFu3bhX+5t+sWbOMNAcAAOAprihUff7552rVqpX27Nmjrl27SpL279/vVuPl5WWuOwAAAA9xRaGqbdu2On78uDZs2CDpmz9LM3fuXIWEhFyT5gAAADzFFd1TZVmW2+t169apsLDQaEMAAACeqEo3qpf7dsgCAACora4oVHl5eVW4Z4p7qAAAAK7wnirLsvTII4/YfzT5/Pnzevzxxyt8++/tt9821yEAAIAHuKJQNXz4cLfXDz30kNFmAAAAPNUVhao33njjWvUBAADg0a7qRnUAAAB8g1AFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGeFSoeuGFF+Tl5aUxY8bY686fP6+EhAQ1adJEDRo00KBBg5SXl+f2vtzcXMXGxqpevXoKDg7W+PHjdeHCBbeaDz/8UF27dpWfn5/atGmjhQsXVtj//Pnz1apVK/n7+ysiIkJbt269FocJAAA8kMeEqm3btukvf/mLfvKTn7itHzt2rN555x2tWLFCGzdu1LFjxzRw4EB7vLS0VLGxsSouLtaWLVu0aNEiLVy4UFOmTLFrDh8+rNjYWPXt21fZ2dkaM2aMfv3rX+u9996za5YtW6akpCRNnTpVO3bs0G233aaYmBidOHHi2h88AACo8bwsy7Kqu4kfcvbsWXXt2lWvvPKKnn/+eXXp0kWzZ89WQUGBmjVrpiVLluhXv/qVJGnfvn3q0KGDMjIy1KNHD61bt0733HOPjh07ppCQEElSSkqKJk6cqJMnT8rX11cTJ07U2rVrtWfPHnufQ4YMUX5+vlJTUyVJERERuuOOOzRv3jxJUllZmcLDw/XUU09p0qRJlToOl8ulwMBAFRQUyOFwmJwiALiuWk1aW90t4Br74oXY6m6hxqjs72+PuFKVkJCg2NhYRUVFua3PyspSSUmJ2/r27dvrpptuUkZGhiQpIyNDnTt3tgOVJMXExMjlcmnv3r12zbe3HRMTY2+juLhYWVlZbjXe3t6KioqyawAAQO3mU90N/JClS5dqx44d2rZtW4Uxp9MpX19fBQUFua0PCQmR0+m0ay4NVOXj5WPfV+NyufT111/r9OnTKi0tvWzNvn37vrP3oqIiFRUV2a9dLtcPHC0AAPBUNfpK1ZEjRzR69GgtXrxY/v7+1d3OFZs+fboCAwPtJTw8vLpbAgAA10iNDlVZWVk6ceKEunbtKh8fH/n4+Gjjxo2aO3eufHx8FBISouLiYuXn57u9Ly8vT6GhoZKk0NDQCt8GLH/9QzUOh0MBAQFq2rSp6tSpc9ma8m1cTnJysgoKCuzlyJEjVZoHAABQ89XoUNWvXz/t3r1b2dnZ9tK9e3fFxcXZ/7tu3bpav369/Z6cnBzl5uYqMjJSkhQZGandu3e7fUsvLS1NDodDHTt2tGsu3UZ5Tfk2fH191a1bN7easrIyrV+/3q65HD8/PzkcDrcFAADcmGr0PVUNGzZUp06d3NbVr19fTZo0sdfHx8crKSlJjRs3lsPh0FNPPaXIyEj16NFDkhQdHa2OHTvq4Ycf1owZM+R0OjV58mQlJCTIz89PkvT4449r3rx5mjBhgh599FGlp6dr+fLlWrv24rdbkpKSNHz4cHXv3l0//elPNXv2bBUWFmrEiBHXaTYAAEBNVqNDVWW8/PLL8vb21qBBg1RUVKSYmBi98sor9nidOnW0Zs0aPfHEE4qMjFT9+vU1fPhwPffcc3ZN69attXbtWo0dO1Zz5sxRixYt9Le//U0xMTF2zeDBg3Xy5ElNmTJFTqdTXbp0UWpqaoWb1wEAQO3kEc+pulHwnCoANwqeU3Xj4zlVF91Qz6kCAACo6QhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYIBPdTcAAABqnlaT1lZ3C9/rixdiq7uFCrhSBQAAYAChCgAAwABCFQAAgAHcUwUANVBNv58FQEVcqQIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABtToUDV9+nTdcccdatiwoYKDgzVgwADl5OS41Zw/f14JCQlq0qSJGjRooEGDBikvL8+tJjc3V7GxsapXr56Cg4M1fvx4Xbhwwa3mww8/VNeuXeXn56c2bdpo4cKFFfqZP3++WrVqJX9/f0VERGjr1q3GjxkAAHimGh2qNm7cqISEBP373/9WWlqaSkpKFB0drcLCQrtm7Nixeuedd7RixQpt3LhRx44d08CBA+3x0tJSxcbGqri4WFu2bNGiRYu0cOFCTZkyxa45fPiwYmNj1bdvX2VnZ2vMmDH69a9/rffee8+uWbZsmZKSkjR16lTt2LFDt912m2JiYnTixInrMxkAAKBG87Isy6ruJirr5MmTCg4O1saNG9WnTx8VFBSoWbNmWrJkiX71q19Jkvbt26cOHTooIyNDPXr00Lp163TPPffo2LFjCgkJkSSlpKRo4sSJOnnypHx9fTVx4kStXbtWe/bssfc1ZMgQ5efnKzU1VZIUERGhO+64Q/PmzZMklZWVKTw8XE899ZQmTZpUqf5dLpcCAwNVUFAgh8NhcmoA3GBaTVpb3S0ANdoXL8Ret31V9vd3jb5S9W0FBQWSpMaNG0uSsrKyVFJSoqioKLumffv2uummm5SRkSFJysjIUOfOne1AJUkxMTFyuVzau3evXXPpNspryrdRXFysrKwstxpvb29FRUXZNZdTVFQkl8vltgAAgBuTx4SqsrIyjRkzRnfeeac6deokSXI6nfL19VVQUJBbbUhIiJxOp11zaaAqHy8f+74al8ulr7/+Wv/5z39UWlp62ZrybVzO9OnTFRgYaC/h4eFXfuAAAMAjeEyoSkhI0J49e7R06dLqbqXSkpOTVVBQYC9Hjhyp7pYAAMA14lPdDVRGYmKi1qxZo02bNqlFixb2+tDQUBUXFys/P9/talVeXp5CQ0Ptmm9/S6/824GX1nz7G4N5eXlyOBwKCAhQnTp1VKdOncvWlG/jcvz8/OTn53flBwwAADxOjb5SZVmWEhMTtXLlSqWnp6t169Zu4926dVPdunW1fv16e11OTo5yc3MVGRkpSYqMjNTu3bvdvqWXlpYmh8Ohjh072jWXbqO8pnwbvr6+6tatm1tNWVmZ1q9fb9cAAIDarUZfqUpISNCSJUv0r3/9Sw0bNrTvXwoMDFRAQIACAwMVHx+vpKQkNW7cWA6HQ0899ZQiIyPVo0cPSVJ0dLQ6duyohx9+WDNmzJDT6dTkyZOVkJBgX0V6/PHHNW/ePE2YMEGPPvqo0tPTtXz5cq1de/HbN0lJSRo+fLi6d++un/70p5o9e7YKCws1YsSI6z8xAACgxqnRoWrBggWSpJ///Odu69944w098sgjkqSXX35Z3t7eGjRokIqKihQTE6NXXnnFrq1Tp47WrFmjJ554QpGRkapfv76GDx+u5557zq5p3bq11q5dq7Fjx2rOnDlq0aKF/va3vykmJsauGTx4sE6ePKkpU6bI6XSqS5cuSk1NrXDzOgAAqJ086jlVno7nVAGoLJ5TBXw/nlMFAABwgyJUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADfKq7AQCoDq0mra3uFgDcYLhSBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABjAc6oAXBM8BwpAbcOVKgAAAAMIVVdo/vz5atWqlfz9/RUREaGtW7dWd0sAAKAG4OO/K7Bs2TIlJSUpJSVFERERmj17tmJiYpSTk6Pg4ODqbg8G8dEVAOBKcaXqCsyaNUsjR47UiBEj1LFjR6WkpKhevXp6/fXXq7s1AABQzbhSVUnFxcXKyspScnKyvc7b21tRUVHKyMi47HuKiopUVFRkvy4oKJAkuVyua9usB+g09b3qbgEA4MGu5+/S8n1ZlvW9dYSqSvrPf/6j0tJShYSEuK0PCQnRvn37Lvue6dOn63e/+12F9eHh4dekRwAAaovA2dd/n2fOnFFgYOB3jhOqrqHk5GQlJSXZr/Pz89WyZUvl5uZ+73+U2sDlcik8PFxHjhyRw+Go7naqFXNxEXNxEXNxEXNxEXNx0fWcC8uydObMGYWFhX1vHaGqkpo2bao6deooLy/PbX1eXp5CQ0Mv+x4/Pz/5+flVWB8YGFjrfxjKORwO5uL/Yy4uYi4uYi4uYi4uYi4uul5zUZmLIdyoXkm+vr7q1q2b1q9fb68rKyvT+vXrFRkZWY2dAQCAmoArVVcgKSlJw4cPV/fu3fXTn/5Us2fPVmFhoUaMGFHdrQEAgGpGqLoCgwcP1smTJzVlyhQ5nU516dJFqampFW5e/y5+fn6aOnXqZT8SrG2Yi4uYi4uYi4uYi4uYi4uYi4tq4lx4WT/0/UAAAAD8IO6pAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEqiu0adMm3XvvvQoLC5OXl5dWrVrlNp6Xl6dHHnlEYWFhqlevnvr3768DBw641fz85z+Xl5eX2/L444+71eTm5io2Nlb16tVTcHCwxo8frwsXLlzrw7siJuZCkjIyMvSLX/xC9evXl8PhUJ8+ffT111/b46dOnVJcXJwcDoeCgoIUHx+vs2fPXuvDuyJXOxdffPFFhXOifFmxYoVdV1vOC6fTqYcfflihoaGqX7++unbtqn/+859uNbXhvJCkQ4cO6f7771ezZs3kcDj0wAMPVHgIsSfMxfTp03XHHXeoYcOGCg4O1oABA5STk+NWc/78eSUkJKhJkyZq0KCBBg0aVOFYK/Mz8OGHH6pr167y8/NTmzZttHDhwmt9eFfE1Fz85je/Ubdu3eTn56cuXbpcdl+7du1S79695e/vr/DwcM2YMeNaHVaVmJiLTz75REOHDlV4eLgCAgLUoUMHzZkzp8K+rsd5Qai6QoWFhbrttts0f/78CmOWZWnAgAH6/PPP9a9//Us7d+5Uy5YtFRUVpcLCQrfakSNH6vjx4/Zy6YleWlqq2NhYFRcXa8uWLVq0aJEWLlyoKVOmXPPjuxIm5iIjI0P9+/dXdHS0tm7dqm3btikxMVHe3hdPzbi4OO3du1dpaWlas2aNNm3apFGjRl2XY6ysq52L8PBwt/Ph+PHj+t3vfqcGDRrorrvuklS7zothw4YpJydHq1ev1u7duzVw4EA98MAD2rlzp11TG86LwsJCRUdHy8vLS+np6dq8ebOKi4t17733qqyszN6WJ8zFxo0blZCQoH//+99KS0tTSUmJoqOj3f67jx07Vu+8845WrFihjRs36tixYxo4cKA9XpmfgcOHDys2NlZ9+/ZVdna2xowZo1//+td6772a80fcTcxFuUcffVSDBw++7H5cLpeio6PVsmVLZWVl6aWXXtK0adP06quvXrNju1Im5iIrK0vBwcF66623tHfvXj3zzDNKTk7WvHnz7Jrrdl5YqDJJ1sqVK+3XOTk5liRrz5499rrS0lKrWbNm1l//+ld73c9+9jNr9OjR37ndd9991/L29racTqe9bsGCBZbD4bCKioqMHoMpVZ2LiIgIa/Lkyd+53U8//dSSZG3bts1et27dOsvLy8v66quvzB6EIVWdi2/r0qWL9eijj9qva9N5Ub9+fevNN99021bjxo3tmtpyXrz33nuWt7e3VVBQYNfk5+dbXl5eVlpammVZnjkXlmVZJ06csCRZGzdutCzrm+OqW7eutWLFCrvms88+syRZGRkZlmVV7mdgwoQJ1q233uq2r8GDB1sxMTHX+pCqrCpzcampU6dat912W4X1r7zyitWoUSO3fx8mTpxotWvXzvxBGHK1c1HuySeftPr27Wu/vl7nBVeqDCoqKpIk+fv72+u8vb3l5+enjz/+2K128eLFatq0qTp16qTk5GSdO3fOHsvIyFDnzp3dHioaExMjl8ulvXv3XuOjMKMyc3HixAllZmYqODhYPXv2VEhIiH72s5+5zVVGRoaCgoLUvXt3e11UVJS8vb2VmZl5nY7m6lzJeVEuKytL2dnZio+Pt9fVlvNCknr27Klly5bp1KlTKisr09KlS3X+/Hn9/Oc/l1R7zouioiJ5eXm5PdzQ399f3t7edo2nzkVBQYEkqXHjxpK+OedLSkoUFRVl17Rv31433XSTMjIyJFXuZyAjI8NtG+U15duoiaoyF5WRkZGhPn36yNfX114XExOjnJwcnT592lD3Zpmai4KCAnsb0vU7LwhVBpX/h05OTtbp06dVXFysF198UUePHtXx48ftugcffFBvvfWWNmzYoOTkZP3973/XQw89ZI87nc4KT2kvf+10Oq/PwVylyszF559/LkmaNm2aRo4cqdTUVHXt2lX9+vWz7ytxOp0KDg5227aPj48aN258Q83Ft7322mvq0KGDevbsaa+rLeeFJC1fvlwlJSVq0qSJ/Pz89Nhjj2nlypVq06aNpNpzXvTo0UP169fXxIkTde7cORUWFmrcuHEqLS21azxxLsrKyjRmzBjdeeed6tSpk6RvjsPX11dBQUFutSEhIfZxVOZn4LtqXC6X272aNUVV56IyPO3fDFNzsWXLFi1btsztI/DrdV4QqgyqW7eu3n77be3fv1+NGzdWvXr1tGHDBt11111u9wiNGjVKMTEx6ty5s+Li4vTmm29q5cqVOnToUDV2b1Zl5qL8npDHHntMI0aM0O23366XX35Z7dq10+uvv16d7RtV2fOi3Ndff60lS5a4XaW6UVR2Lp599lnl5+frgw8+0Pbt25WUlKQHHnhAu3fvrsbuzarMXDRr1kwrVqzQO++8owYNGigwMFD5+fnq2rXrZc8dT5GQkKA9e/Zo6dKl1d1KtWMuLjIxF3v27NF9992nqVOnKjo62mB3lcPf/jOsW7duys7OVkFBgYqLi9WsWTNFRES4XZr/toiICEnSwYMHdfPNNys0NFRbt251qyn/pkNoaOi1a96wH5qL5s2bS5I6duzo9r4OHTooNzdX0jfHe+LECbfxCxcu6NSpUzfUXFzq//7v/3Tu3DkNGzbMbX1tOS8OHTqkefPmac+ePbr11lslSbfddps++ugjzZ8/XykpKbXqvIiOjtahQ4f0n//8Rz4+PgoKClJoaKh+/OMfS/K8n5HExET7ZvoWLVrY60NDQ1VcXKz8/Hy3qxJ5eXn2cVTmZyA0NLTCt+Ty8vLkcDgUEBBwLQ6pyq5mLirju+aifKwmMTEXn376qfr166dRo0Zp8uTJbmPX67zw3P+rU8MFBgaqWbNmOnDggLZv36777rvvO2uzs7MlXQwZkZGR2r17t9s/lGlpaXI4HBUCiCf4rrlo1aqVwsLCKnx9dv/+/WrZsqWkb+YiPz9fWVlZ9nh6errKysrsMOpJKnNevPbaa/rlL3+pZs2aua2vLedF+f2F374SU6dOHfvqZm08L5o2baqgoCClp6frxIkT+uUvfynJc+bCsiwlJiZq5cqVSk9PV+vWrd3Gu3Xrprp162r9+vX2upycHOXm5ioyMlJS5X4GIiMj3bZRXlO+jZrAxFxURmRkpDZt2qSSkhJ7XVpamtq1a6dGjRpd/YEYYGou9u7dq759+2r48OH6wx/+UGE/1+28MHrbey1w5swZa+fOndbOnTstSdasWbOsnTt3Wl9++aVlWZa1fPlya8OGDdahQ4esVatWWS1btrQGDhxov//gwYPWc889Z23fvt06fPiw9a9//cv68Y9/bPXp08euuXDhgtWpUycrOjrays7OtlJTU61mzZpZycnJ1/14v8/VzoVlWdbLL79sORwOa8WKFdaBAwesyZMnW/7+/tbBgwftmv79+1u33367lZmZaX388cdW27ZtraFDh17XY/0hJubCsizrwIEDlpeXl7Vu3boKY7XlvCguLrbatGlj9e7d28rMzLQOHjxo/elPf7K8vLystWvX2nW15bx4/fXXrYyMDOvgwYPW3//+d6tx48ZWUlKSW40nzMUTTzxhBQYGWh9++KF1/Phxezl37pxd8/jjj1s33XSTlZ6ebm3fvt2KjIy0IiMj7fHK/Ax8/vnnVr169azx48dbn332mTV//nyrTp06Vmpq6nU93u9jYi4s65t/L3bu3Gk99thj1i233GKfa+Xf9svPz7dCQkKshx9+2NqzZ4+1dOlSq169etZf/vKX63q838fEXOzevdtq1qyZ9dBDD7lt48SJE3bN9TovCFVXaMOGDZakCsvw4cMty7KsOXPmWC1atLDq1q1r3XTTTdbkyZPdvs6am5tr9enTx2rcuLHl5+dntWnTxho/frzbV6Yty7K++OIL66677rICAgKspk2bWk8//bRVUlJyPQ/1B13tXJSbPn261aJFC6tevXpWZGSk9dFHH7mN//e//7WGDh1qNWjQwHI4HNaIESOsM2fOXI9DrDRTc5GcnGyFh4dbpaWll91PbTkv9u/fbw0cONAKDg626tWrZ/3kJz+p8IiF2nJeTJw40QoJCbHq1q1rtW3b1po5c6ZVVlbmVuMJc3G5eZBkvfHGG3bN119/bT355JNWo0aNrHr16ln333+/dfz4cbftVOZnYMOGDVaXLl0sX19f68c//rHbPmoCU3Pxs5/97LLbOXz4sF3zySefWL169bL8/PysH/3oR9YLL7xwnY6yckzMxdSpUy+7jZYtW7rt63qcF17//6AAAABwFbinCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAG/D9aoAUHafFecgAAAABJRU5ErkJggg==","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["data['price'].plot(kind='hist', bins=200)\n","plt.show()\n","data['registration_year'].plot(kind='hist', bins=1500, xlim=(1950, 2024))\n","plt.show()\n","data['power'].plot(kind='hist', bins=200, xlim=(0,1000))\n","plt.show()\n","data['kilometer'].plot(kind='hist', bins=100)\n","plt.show()"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_ca801\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_ca801_level0_col0\" class=\"col_heading level0 col0\" >price</th>\n","      <th id=\"T_ca801_level0_col1\" class=\"col_heading level0 col1\" >registration_year</th>\n","      <th id=\"T_ca801_level0_col2\" class=\"col_heading level0 col2\" >power</th>\n","      <th id=\"T_ca801_level0_col3\" class=\"col_heading level0 col3\" >kilometer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_ca801_level0_row0\" class=\"row_heading level0 row0\" >0.001200</th>\n","      <td id=\"T_ca801_row0_col0\" class=\"data row0 col0\" >0.00</td>\n","      <td id=\"T_ca801_row0_col1\" class=\"data row0 col1\" >1,960.00</td>\n","      <td id=\"T_ca801_row0_col2\" class=\"data row0 col2\" >0.00</td>\n","      <td id=\"T_ca801_row0_col3\" class=\"data row0 col3\" >5,000.00</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ca801_level0_row1\" class=\"row_heading level0 row1\" >0.050000</th>\n","      <td id=\"T_ca801_row1_col0\" class=\"data row1 col0\" >200.00</td>\n","      <td id=\"T_ca801_row1_col1\" class=\"data row1 col1\" >1,992.00</td>\n","      <td id=\"T_ca801_row1_col2\" class=\"data row1 col2\" >0.00</td>\n","      <td id=\"T_ca801_row1_col3\" class=\"data row1 col3\" >40,000.00</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ca801_level0_row2\" class=\"row_heading level0 row2\" >0.500000</th>\n","      <td id=\"T_ca801_row2_col0\" class=\"data row2 col0\" >2,700.00</td>\n","      <td id=\"T_ca801_row2_col1\" class=\"data row2 col1\" >2,003.00</td>\n","      <td id=\"T_ca801_row2_col2\" class=\"data row2 col2\" >105.00</td>\n","      <td id=\"T_ca801_row2_col3\" class=\"data row2 col3\" >150,000.00</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ca801_level0_row3\" class=\"row_heading level0 row3\" >0.950000</th>\n","      <td id=\"T_ca801_row3_col0\" class=\"data row3 col0\" >14,600.00</td>\n","      <td id=\"T_ca801_row3_col1\" class=\"data row3 col1\" >2,016.00</td>\n","      <td id=\"T_ca801_row3_col2\" class=\"data row3 col2\" >218.00</td>\n","      <td id=\"T_ca801_row3_col3\" class=\"data row3 col3\" >150,000.00</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_ca801_level0_row4\" class=\"row_heading level0 row4\" >0.998800</th>\n","      <td id=\"T_ca801_row4_col0\" class=\"data row4 col0\" >19,999.00</td>\n","      <td id=\"T_ca801_row4_col1\" class=\"data row4 col1\" >2,018.00</td>\n","      <td id=\"T_ca801_row4_col2\" class=\"data row4 col2\" >520.00</td>\n","      <td id=\"T_ca801_row4_col3\" class=\"data row4 col3\" >150,000.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x1abc8749850>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["(\n","    data[['price', 'registration_year', 'power', 'kilometer']]\n","    .quantile([0.0012, 0.05, .5, .95, .9988])\n","    .style.format(\"{:,.2f}\")\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["# Удаление аномалий\n","data = data[data['price'] > 200]\n","data = data[data['registration_year'] <= 2024]\n","data = data[(data['power'] > 18) & (data['power'] < 1000)]"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div class=\"alert alert-block alert-success\">\n","<b>Успех:</b>  Самое интересное, что на нескольких сайтов по продажам подержанных автомобилей в Германии (страну можно определить по почтовым индексам, большинство из них из Германии) показало, что цены начинаются действительно с 0 и 1 евро, но это единичные объявления и не понятно, то ли это ошибка при заполнении формы, то ли машины на металлолом. Но я  все-таки склоняюсь к тому, чтобы избавиться от таких данных\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div class=\"alert alert-block alert-info\">\n","<b>Совет:</b>\n","    \n","- Советую посмотреть на дату выгрузки анкет - там тоже можно увидеть полезную информацию по поводу границ года регистраци.\n","\n","- Вопрос на подумать: Как думаешь а машины с 0-ой мощностью могут быть просто без двигателя?\n","</div>\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_48d76\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_48d76_level0_col0\" class=\"col_heading level0 col0\" >price</th>\n","      <th id=\"T_48d76_level0_col1\" class=\"col_heading level0 col1\" >registration_year</th>\n","      <th id=\"T_48d76_level0_col2\" class=\"col_heading level0 col2\" >power</th>\n","      <th id=\"T_48d76_level0_col3\" class=\"col_heading level0 col3\" >kilometer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_48d76_level0_row0\" class=\"row_heading level0 row0\" >0.001200</th>\n","      <td id=\"T_48d76_row0_col0\" class=\"data row0 col0\" >249.00</td>\n","      <td id=\"T_48d76_row0_col1\" class=\"data row0 col1\" >1,965.00</td>\n","      <td id=\"T_48d76_row0_col2\" class=\"data row0 col2\" >26.00</td>\n","      <td id=\"T_48d76_row0_col3\" class=\"data row0 col3\" >5,000.00</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_48d76_level0_row1\" class=\"row_heading level0 row1\" >0.050000</th>\n","      <td id=\"T_48d76_row1_col0\" class=\"data row1 col0\" >500.00</td>\n","      <td id=\"T_48d76_row1_col1\" class=\"data row1 col1\" >1,993.00</td>\n","      <td id=\"T_48d76_row1_col2\" class=\"data row1 col2\" >55.00</td>\n","      <td id=\"T_48d76_row1_col3\" class=\"data row1 col3\" >40,000.00</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_48d76_level0_row2\" class=\"row_heading level0 row2\" >0.500000</th>\n","      <td id=\"T_48d76_row2_col0\" class=\"data row2 col0\" >3,200.00</td>\n","      <td id=\"T_48d76_row2_col1\" class=\"data row2 col1\" >2,003.00</td>\n","      <td id=\"T_48d76_row2_col2\" class=\"data row2 col2\" >113.00</td>\n","      <td id=\"T_48d76_row2_col3\" class=\"data row2 col3\" >150,000.00</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_48d76_level0_row3\" class=\"row_heading level0 row3\" >0.950000</th>\n","      <td id=\"T_48d76_row3_col0\" class=\"data row3 col0\" >14,999.00</td>\n","      <td id=\"T_48d76_row3_col1\" class=\"data row3 col1\" >2,016.00</td>\n","      <td id=\"T_48d76_row3_col2\" class=\"data row3 col2\" >224.00</td>\n","      <td id=\"T_48d76_row3_col3\" class=\"data row3 col3\" >150,000.00</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_48d76_level0_row4\" class=\"row_heading level0 row4\" >0.998800</th>\n","      <td id=\"T_48d76_row4_col0\" class=\"data row4 col0\" >19,999.00</td>\n","      <td id=\"T_48d76_row4_col1\" class=\"data row4 col1\" >2,018.00</td>\n","      <td id=\"T_48d76_row4_col2\" class=\"data row4 col2\" >420.00</td>\n","      <td id=\"T_48d76_row4_col3\" class=\"data row4 col3\" >150,000.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x1ab96d77ac0>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["(\n","    data[['price', 'registration_year', 'power', 'kilometer']]\n","    .quantile([0.0012, 0.05, .5, .95, .9988])\n","    .style.format(\"{:,.2f}\")\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 301218 entries, 1 to 354368\n","Data columns (total 10 columns):\n"," #   Column             Non-Null Count   Dtype \n","---  ------             --------------   ----- \n"," 0   price              301218 non-null  int64 \n"," 1   vehicle_type       280945 non-null  object\n"," 2   registration_year  301218 non-null  int64 \n"," 3   gearbox            295519 non-null  object\n"," 4   power              301218 non-null  int64 \n"," 5   model              289446 non-null  object\n"," 6   kilometer          301218 non-null  int64 \n"," 7   fuel_type          282527 non-null  object\n"," 8   brand              301218 non-null  object\n"," 9   repaired           256175 non-null  object\n","dtypes: int64(4), object(6)\n","memory usage: 25.3+ MB\n"]}],"source":["data.info()"]},{"cell_type":"markdown","metadata":{},"source":["#### Обработка пропусков"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["price                 0.000000\n","vehicle_type          6.730341\n","registration_year     0.000000\n","gearbox               1.891985\n","power                 0.000000\n","model                 3.908133\n","kilometer             0.000000\n","fuel_type             6.205140\n","brand                 0.000000\n","repaired             14.953622\n","dtype: float64"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["data.isnull().sum()*100/len(data)"]},{"cell_type":"markdown","metadata":{},"source":["Пропуски в категориальных переменных заполним значением \"unknown\"."]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["vehicle_type\n","sedan          82214\n","small          67544\n","wagon          58688\n","bus            26100\n","convertible    18688\n","coupe          14412\n","suv            10931\n","other           2368\n","Name: count, dtype: int64"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data['vehicle_type'].value_counts()"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["data['vehicle_type'] = data['vehicle_type'].fillna('unknown')"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["model\n","golf                  25552\n","other                 20418\n","3er                   17639\n","polo                  10657\n","corsa                  9947\n","                      ...  \n","i3                        5\n","samara                    5\n","rangerover                3\n","serie_3                   3\n","range_rover_evoque        2\n","Name: count, Length: 249, dtype: int64"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["data['model'].value_counts()"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["data['model'] = data['model'].fillna('unknown')"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["fuel_type\n","petrol      187792\n","gasoline     89145\n","lpg           4767\n","cng            495\n","hybrid         204\n","other           81\n","electric        43\n","Name: count, dtype: int64"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["data['fuel_type'].value_counts()"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["data['fuel_type'] = data['fuel_type'].fillna('unknown')"]},{"cell_type":"markdown","metadata":{},"source":["Пропуски в колонках с двумя значениеми заполним предыдущим значением признака."]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["gearbox\n","manual    235676\n","auto       59843\n","Name: count, dtype: int64"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["data['gearbox'].value_counts()"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["repaired\n","no     228548\n","yes     27627\n","Name: count, dtype: int64"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["data['repaired'].value_counts()"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["data['gearbox'] = data['gearbox'].ffill()\n","data['repaired'] = data['repaired'].ffill()"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["price                0.0\n","vehicle_type         0.0\n","registration_year    0.0\n","gearbox              0.0\n","power                0.0\n","model                0.0\n","kilometer            0.0\n","fuel_type            0.0\n","brand                0.0\n","repaired             0.0\n","dtype: float64"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["data.isnull().sum()*100/len(data)"]},{"cell_type":"markdown","metadata":{},"source":["Пропуски заполнены."]},{"cell_type":"markdown","metadata":{},"source":["#### Преобразование некоторых колонок к булеву типу"]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[],"source":["data['gearbox'] = data['gearbox'] == 'auto'\n","data['repaired'] = data['repaired'] == 'yes'"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["gearbox\n","False    240208\n","True      61010\n","Name: count, dtype: int64"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["data['gearbox'].value_counts()"]},{"cell_type":"code","execution_count":33,"metadata":{"scrolled":true,"trusted":true},"outputs":[{"data":{"text/plain":["repaired\n","False    268806\n","True      32412\n","Name: count, dtype: int64"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["data['repaired'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div class=\"alert alert-block alert-success\">\n","<b>Успех:</b>  Пропуски обработаны хорошим образом\n","</div>\n","\n","\n","<div class=\"alert alert-block alert-info\">\n","<b>Совет:</b> У fuel_type есть категории, которые означают одно и тоже - их можно объединить, либо подумать может они действительно означают, что-то разное.\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Вывод по разделу"]},{"cell_type":"markdown","metadata":{},"source":["* Удалены ненужные колонки.\n","* Названия колонок приведены к нижнему регистру.\n","* Удалены аномалии в количественных признаках.\n","* Пропуски в колонках (vehicle_type, model, fuel_type) заполнены заглушкой unknown, а в колонках gearbox и repaired предыдущим значение.\n","* В колонках gearbox и repaired тип изменен на логический.\n","* Найдены дубликаты, однако было решено их оставить."]},{"cell_type":"markdown","metadata":{},"source":["\n","<div class=\"alert alert-block alert-success\">\n","<b>Успех:</b> В целом хорошая, детальная предобработка - идем дальше\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Подготовка выборки к обучению"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>price</th>\n","      <th>vehicle_type</th>\n","      <th>registration_year</th>\n","      <th>gearbox</th>\n","      <th>power</th>\n","      <th>model</th>\n","      <th>kilometer</th>\n","      <th>fuel_type</th>\n","      <th>brand</th>\n","      <th>repaired</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>18300</td>\n","      <td>coupe</td>\n","      <td>2011</td>\n","      <td>False</td>\n","      <td>190</td>\n","      <td>unknown</td>\n","      <td>125000</td>\n","      <td>gasoline</td>\n","      <td>audi</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9800</td>\n","      <td>suv</td>\n","      <td>2004</td>\n","      <td>True</td>\n","      <td>163</td>\n","      <td>grand</td>\n","      <td>125000</td>\n","      <td>gasoline</td>\n","      <td>jeep</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1500</td>\n","      <td>small</td>\n","      <td>2001</td>\n","      <td>False</td>\n","      <td>75</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   price vehicle_type  registration_year  gearbox  power    model  kilometer  \\\n","1  18300        coupe               2011    False    190  unknown     125000   \n","2   9800          suv               2004     True    163    grand     125000   \n","3   1500        small               2001    False     75     golf     150000   \n","\n","  fuel_type       brand  repaired  \n","1  gasoline        audi      True  \n","2  gasoline        jeep      True  \n","3    petrol  volkswagen     False  "]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["data.head(3)"]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>price</th>\n","      <th>vehicle_type</th>\n","      <th>registration_year</th>\n","      <th>gearbox</th>\n","      <th>power</th>\n","      <th>model</th>\n","      <th>kilometer</th>\n","      <th>fuel_type</th>\n","      <th>brand</th>\n","      <th>repaired</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>18300</td>\n","      <td>coupe</td>\n","      <td>2011</td>\n","      <td>0</td>\n","      <td>190</td>\n","      <td>unknown</td>\n","      <td>125000</td>\n","      <td>gasoline</td>\n","      <td>audi</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9800</td>\n","      <td>suv</td>\n","      <td>2004</td>\n","      <td>1</td>\n","      <td>163</td>\n","      <td>grand</td>\n","      <td>125000</td>\n","      <td>gasoline</td>\n","      <td>jeep</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1500</td>\n","      <td>small</td>\n","      <td>2001</td>\n","      <td>0</td>\n","      <td>75</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   price vehicle_type  registration_year  gearbox  power    model  kilometer  \\\n","1  18300        coupe               2011        0    190  unknown     125000   \n","2   9800          suv               2004        1    163    grand     125000   \n","3   1500        small               2001        0     75     golf     150000   \n","\n","  fuel_type       brand  repaired  \n","1  gasoline        audi         1  \n","2  gasoline        jeep         1  \n","3    petrol  volkswagen         0  "]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["data['gearbox'] = data['gearbox'].astype(int)\n","data['repaired'] = data['repaired'].astype(int)\n","data.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Изменения:</b> разбил выборку до encoder'а и сделал 2 отдельные выборки с кодировками ohe и oe (переписал их с использованием sklearn классов).\n","</div>"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["features = data.drop('price', axis=1)\n","target = data['price']\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=.25, random_state=RANDOM_STATE)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["['vehicle_type', 'model', 'fuel_type', 'brand']"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["ohe_features_ridge = X_train.select_dtypes(include='object').columns.to_list()\n","ohe_features_ridge"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["['registration_year', 'power', 'kilometer']"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["num_features = X_train.select_dtypes(exclude='object').columns.to_list()\n","num_features.remove('repaired')\n","num_features.remove('gearbox')\n","num_features"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["X_train_ridge = X_train.copy()\n","X_test_ridge = X_test.copy()"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n","C:\\Users\\klpkv\\AppData\\Local\\Temp\\ipykernel_11244\\3631712052.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train_ridge[\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>registration_year</th>\n","      <th>gearbox</th>\n","      <th>power</th>\n","      <th>kilometer</th>\n","      <th>repaired</th>\n","      <th>vehicle_type_convertible</th>\n","      <th>vehicle_type_coupe</th>\n","      <th>vehicle_type_other</th>\n","      <th>vehicle_type_sedan</th>\n","      <th>vehicle_type_small</th>\n","      <th>...</th>\n","      <th>brand_seat</th>\n","      <th>brand_skoda</th>\n","      <th>brand_smart</th>\n","      <th>brand_sonstige_autos</th>\n","      <th>brand_subaru</th>\n","      <th>brand_suzuki</th>\n","      <th>brand_toyota</th>\n","      <th>brand_trabant</th>\n","      <th>brand_volkswagen</th>\n","      <th>brand_volvo</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>66897</th>\n","      <td>-0.047640</td>\n","      <td>0</td>\n","      <td>0.397667</td>\n","      <td>0.589168</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>208844</th>\n","      <td>0.595497</td>\n","      <td>0</td>\n","      <td>-0.297756</td>\n","      <td>0.589168</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>200455</th>\n","      <td>0.466869</td>\n","      <td>0</td>\n","      <td>0.013354</td>\n","      <td>-1.596315</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>240865</th>\n","      <td>0.595497</td>\n","      <td>1</td>\n","      <td>0.525771</td>\n","      <td>0.589168</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2434</th>\n","      <td>0.338242</td>\n","      <td>1</td>\n","      <td>1.056488</td>\n","      <td>0.589168</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 307 columns</p>\n","</div>"],"text/plain":["        registration_year  gearbox     power  kilometer  repaired  \\\n","66897           -0.047640        0  0.397667   0.589168         0   \n","208844           0.595497        0 -0.297756   0.589168         0   \n","200455           0.466869        0  0.013354  -1.596315         1   \n","240865           0.595497        1  0.525771   0.589168         0   \n","2434             0.338242        1  1.056488   0.589168         0   \n","\n","        vehicle_type_convertible  vehicle_type_coupe  vehicle_type_other  \\\n","66897                        0.0                 1.0                 0.0   \n","208844                       0.0                 0.0                 0.0   \n","200455                       0.0                 0.0                 0.0   \n","240865                       0.0                 0.0                 0.0   \n","2434                         0.0                 0.0                 0.0   \n","\n","        vehicle_type_sedan  vehicle_type_small  ...  brand_seat  brand_skoda  \\\n","66897                  0.0                 0.0  ...         0.0          0.0   \n","208844                 0.0                 0.0  ...         0.0          0.0   \n","200455                 1.0                 0.0  ...         0.0          0.0   \n","240865                 0.0                 0.0  ...         0.0          0.0   \n","2434                   0.0                 0.0  ...         0.0          0.0   \n","\n","        brand_smart  brand_sonstige_autos  brand_subaru  brand_suzuki  \\\n","66897           0.0                   0.0           0.0           0.0   \n","208844          0.0                   0.0           0.0           0.0   \n","200455          0.0                   0.0           0.0           0.0   \n","240865          0.0                   0.0           0.0           0.0   \n","2434            0.0                   0.0           0.0           0.0   \n","\n","        brand_toyota  brand_trabant  brand_volkswagen  brand_volvo  \n","66897            0.0            0.0               0.0          0.0  \n","208844           0.0            0.0               1.0          0.0  \n","200455           0.0            0.0               0.0          0.0  \n","240865           0.0            0.0               0.0          0.0  \n","2434             0.0            0.0               0.0          0.0  \n","\n","[5 rows x 307 columns]"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["encoder_ohe = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)\n","\n","# обучаем энкодер на заданных категориальных признаках тренировочной выборки\n","encoder_ohe.fit(X_train_ridge[ohe_features_ridge])\n","\n","# добавляем закодированные признаки в X_train_ohe\n","# encoder_ohe.get_feature_names_out() позволяет получить названия колонок\n","X_train_ridge[\n","    encoder_ohe.get_feature_names_out()\n","] = encoder_ohe.transform(X_train_ridge[ohe_features_ridge])\n","\n","# удаляем незакодированные категориальные признаки (изначальные колонки)\n","X_train_ridge = X_train_ridge.drop(ohe_features_ridge, axis=1)\n","\n","# создаём скелер\n","scaler = StandardScaler()\n","\n","# обучаем его на численных признаках тренировочной выборки, трансформируем её же\n","X_train_ridge[num_features] = scaler.fit_transform(X_train_ridge[num_features])\n","\n","# смотрим на результат\n","X_train_ridge.head()"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["X_train_ridge_oe = X_train.copy()\n","X_test_ridge_oe = X_test.copy()"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>vehicle_type</th>\n","      <th>registration_year</th>\n","      <th>gearbox</th>\n","      <th>power</th>\n","      <th>model</th>\n","      <th>kilometer</th>\n","      <th>fuel_type</th>\n","      <th>brand</th>\n","      <th>repaired</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>66897</th>\n","      <td>2.0</td>\n","      <td>-0.047640</td>\n","      <td>0</td>\n","      <td>0.397667</td>\n","      <td>59.0</td>\n","      <td>0.589168</td>\n","      <td>6.0</td>\n","      <td>20.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>208844</th>\n","      <td>8.0</td>\n","      <td>0.595497</td>\n","      <td>0</td>\n","      <td>-0.297756</td>\n","      <td>170.0</td>\n","      <td>0.589168</td>\n","      <td>2.0</td>\n","      <td>38.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>200455</th>\n","      <td>4.0</td>\n","      <td>0.466869</td>\n","      <td>0</td>\n","      <td>0.013354</td>\n","      <td>119.0</td>\n","      <td>-1.596315</td>\n","      <td>6.0</td>\n","      <td>12.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>240865</th>\n","      <td>0.0</td>\n","      <td>0.595497</td>\n","      <td>1</td>\n","      <td>0.525771</td>\n","      <td>117.0</td>\n","      <td>0.589168</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2434</th>\n","      <td>8.0</td>\n","      <td>0.338242</td>\n","      <td>1</td>\n","      <td>1.056488</td>\n","      <td>31.0</td>\n","      <td>0.589168</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        vehicle_type  registration_year  gearbox     power  model  kilometer  \\\n","66897            2.0          -0.047640        0  0.397667   59.0   0.589168   \n","208844           8.0           0.595497        0 -0.297756  170.0   0.589168   \n","200455           4.0           0.466869        0  0.013354  119.0  -1.596315   \n","240865           0.0           0.595497        1  0.525771  117.0   0.589168   \n","2434             8.0           0.338242        1  1.056488   31.0   0.589168   \n","\n","        fuel_type  brand  repaired  \n","66897         6.0   20.0         0  \n","208844        2.0   38.0         0  \n","200455        6.0   12.0         1  \n","240865        2.0    4.0         0  \n","2434          2.0    1.0         0  "]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["encoder_oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n","\n","# обучаем энкодер на заданных категориальных признаках тренировочной выборки\n","encoder_oe.fit(X_train_ridge_oe[ohe_features_ridge])\n","\n","# добавляем закодированные признаки в X_train_ohe\n","# encoder_ohe.get_feature_names_out() позволяет получить названия колонок\n","X_train_ridge_oe[\n","    encoder_oe.get_feature_names_out()\n","] = encoder_oe.transform(X_train_ridge_oe[ohe_features_ridge])\n","\n","# создаём скелер\n","scaler = StandardScaler()\n","\n","# обучаем его на численных признаках тренировочной выборки, трансформируем её же\n","X_train_ridge_oe[num_features] = scaler.fit_transform(X_train_ridge_oe[num_features])\n","\n","\n","X_test_ridge_oe[\n","    encoder_oe.get_feature_names_out()\n","] = encoder_oe.transform(X_test_ridge_oe[ohe_features_ridge])\n","\n","# обучаем его на численных признаках тренировочной выборки, трансформируем её же\n","X_test_ridge_oe[num_features] = scaler.fit_transform(X_test_ridge_oe[num_features])\n","\n","# смотрим на результат\n","X_train_ridge_oe.head()"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-danger\">\n","\n","<b>Ошибка:</b>  OHE (прямое кодирование) правильный выбор для линейных моделей. Но для всех других моделей выбор плохой (из-за фактора модели, который порождает много факторов), для заказчика важно время обучения и скорость предсказания, а данные модели могут работать и с другими методами кодировками значительно быстреее, не теряя при этом в качестве.\n","\n","Я тебе могу предложить, что можно сделать:\n","    \n","- Сделать 1 набор данных: \n","    - Закодировать для всех моделей методом TargetEncoder, BinaryEncoder - вполне универсальные варианты\n","    - Закодировать все признаки методом OHE, а модель машины методом OE\n","    - Заменить использование линейных моделей (так как их рассмотрение не обязательно) и использовать единственный метод кодировки OE.\n","- Сделать 2 набора данных\n","    - Закодировать для линейных моделей методом OHE, для остальных OE (или внутренний метод кодирования данных)\n","    \n","P.S. Отмечу, что encoder правильно применять после разбиения данных и обучать только на обучающей выборке, для остальных выборок просто использовать transform. Примеры использования с объяснениями можно найти посмотреь https://colab.research.google.com/drive/1_gAMXcQKoCShB_l8FNtYEejMnosm9mvt?usp=sharing \n","\n","И не забывай использовать параметр `handle_unknown`\n","  \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    \n","<b>Совет:</b> Также как аналог pd.get_dummies хочу посоветовать обратить внимание на OneHotEncoder от sklearn (это более сложный и продвинутый инструмент). Здесь можно посмотреть примеры https://colab.research.google.com/drive/1_gAMXcQKoCShB_l8FNtYEejMnosm9mvt?usp=sharing\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Выводы по разделу"]},{"cell_type":"markdown","metadata":{},"source":["* Категориальные признаки были преобразованы в численные методом прямого кодирования.\n","* Выборка разбита на тренировочную и тестовую."]},{"cell_type":"markdown","metadata":{},"source":["## Обучение моделей"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Изменения:</b> добавил немного гиперпараметров для бустинга, поставил явный замер времени (у меня локально время выполнения ячейки показывает vs code поэтому сначала замер не ставил), замер времени теперь производится у модели с заранее подобранными гиперапараметрами. \n","</div>"]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":true},"outputs":[],"source":["# Класс для работы с моделями\n","class MultiModelLearning:\n","    def __init__(self, model_name: str):\n","        self.model_name = model_name\n","        if model_name == 'linear_regressor':\n","            self.model = LinearRegression()\n","        elif model_name == 'tree':\n","            self.model = DecisionTreeRegressor(random_state=RANDOM_STATE)\n","        elif model_name == 'bagging':\n","            self.model = BaggingRegressor(random_state=RANDOM_STATE)\n","        elif model_name == 'boosting':\n","            self.model = LGBMRegressor(random_state=RANDOM_STATE)\n","        elif model_name == 'dummy':\n","            self.model = DummyRegressor(strategy=\"mean\")\n","        else:\n","            display(\"Было введено неверное имя модели\")\n","        self.features = None\n","        self.target = None\n","        self.best_model = None\n","        self.best_score = None\n","        self.best_params = None\n","        self.results = None\n","\n","    # Подбор гиперпараметров для модели\n","    def select_hyperparameters__(self, param_dist):\n","        grid_search = GridSearchCV(self.model, param_grid=param_dist, cv=5, scoring='neg_root_mean_squared_error')\n","        grid_search.fit(self.features, self.target)\n","        self.best_model = grid_search.best_estimator_\n","        self.hyperparameters = grid_search.best_params_\n","        self.best_score = -grid_search.best_score_\n","        self.results = grid_search.cv_results_\n","        \n","\n","    # Функции обучения моделей\n","    def learn_linear_regression__(self): \n","        self.best_score = -sum(cross_val_score(self.model, self.features, self.target, cv=5, scoring='neg_root_mean_squared_error'))/5\n","    \n","    def learn_tree__(self):\n","        param_dist = {\n","            'max_depth': [i for i in range(1,15)]\n","        }\n","        self.select_hyperparameters__(param_dist)\n","\n","    def learn_bagging__(self):\n","        param_dist = {\n","            'n_estimators': [i for i in range(1, 8)],\n","        }\n","        self.select_hyperparameters__(param_dist)\n","        \n","    def learn_boosting__(self):\n","        param_dist = {\n","            'n_estimators': [2,5,10,25,50,100],\n","            'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]\n","        }\n","        self.select_hyperparameters__(param_dist)\n","\n","    def learn_dummy__(self):\n","        self.best_model = self.model.fit(self.features, self.target)\n","        self.best_score = -sum(cross_val_score(self.model, self.features, self.target, cv=5, scoring='neg_root_mean_squared_error'))/5\n","\n","\n","    def select_model__(self):\n","        if self.model_name == 'linear_regressor':\n","            self.learn_linear_regression__()\n","        elif self.model_name == 'tree':\n","            self.learn_tree__()\n","        elif self.model_name == 'bagging':\n","            self.learn_bagging__()\n","        elif self.model_name == 'boosting':\n","            self.learn_boosting__()\n","        elif self.model_name == 'dummy':\n","            self.learn_dummy__()\n","        else:\n","            display(\"Было введено неверное имя модели\")\n","\n","    def fit(self, features, target):\n","        self.features = features\n","        self.target = target\n","        self.select_model__()\n","\n","\n","    # Предсказание модели\n","    def predict(self, features):\n","        model_predictions = self.best_model.predict(features)\n","        return model_predictions\n","\n","    def new_learn(self):\n","        self.model.set_params(**self.hyperparameters)\n","        self.model.fit(self.features, self.target)"]},{"cell_type":"markdown","metadata":{},"source":["\n","<div class=\"alert alert-block alert-success\">\n","<b>Успех:</b>  Хороший помощник, лайк за ООП. Но гиперпараметры  для моделей выглядят скудно, особенно для бустингов - над этим можно поработать"]},{"cell_type":"markdown","metadata":{},"source":["### Обучение линейной решнессии"]},{"cell_type":"code","execution_count":44,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 1min 31s\n","Wall time: 18.3 s\n"]},{"data":{"text/plain":["2736.2379883012823"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","linear_regression = MultiModelLearning('linear_regressor')\n","linear_regression.fit(X_train_ridge, y_train)\n","linear_regression.best_score"]},{"cell_type":"markdown","metadata":{},"source":["### Обучение дерева решений"]},{"cell_type":"code","execution_count":45,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["1914.055135407237"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["tree = MultiModelLearning('tree')\n","tree.fit(X_train_ridge_oe, y_train)\n","tree.best_score"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 422 ms\n","Wall time: 419 ms\n"]}],"source":["%%time\n","tree.new_learn()"]},{"cell_type":"markdown","metadata":{},"source":["### Обучение бэггинга"]},{"cell_type":"code","execution_count":47,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["1706.3234456762882"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["bagging = MultiModelLearning('bagging')\n","bagging.fit(X_train_ridge_oe, y_train)\n","bagging.best_score"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 2.94 s\n","Wall time: 2.99 s\n"]}],"source":["%%time\n","bagging.new_learn()"]},{"cell_type":"markdown","metadata":{},"source":["### Обучение бустинга"]},{"cell_type":"code","execution_count":49,"metadata":{"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003542 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003727 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003207 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003739 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003517 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002420 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003383 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003090 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002981 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003106 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002991 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002884 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003295 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003209 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003340 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002928 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002995 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003168 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002979 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003603 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003075 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003365 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003067 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003692 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003667 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003347 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003455 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002377 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003577 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003985 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002954 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003037 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003139 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002740 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003037 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002902 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003202 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003050 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002912 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003104 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003008 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003614 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004006 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003244 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003193 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003329 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003099 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003201 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003254 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003148 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003657 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003170 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003122 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003086 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003353 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003390 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002857 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003343 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003526 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003220 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003640 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003143 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003194 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003531 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003274 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003025 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003166 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003123 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003264 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003264 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003191 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002877 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002938 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003286 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003093 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003660 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003096 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003097 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002995 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003371 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003065 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003235 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002912 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003412 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003494 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002867 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003101 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003101 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003176 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003710 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003360 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003435 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003126 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003290 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002863 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003170 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003141 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002874 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003619 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003427 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003324 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003161 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002941 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003419 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003858 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002975 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003234 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003013 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039186 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002980 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003201 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003423 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002966 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003078 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002627 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003370 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003262 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003073 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003250 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003087 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003415 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003070 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003070 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003394 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003653 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003393 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003472 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003095 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002934 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002570 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002906 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003337 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002936 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003303 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003324 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003373 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003112 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003231 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003492 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003339 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002784 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003721 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003226 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003124 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003132 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003351 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003146 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002896 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003460 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003231 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002838 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003594 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002778 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003124 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003112 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003000 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002912 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002576 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003378 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003061 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003423 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003299 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003085 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003711 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003062 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003109 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003512 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002862 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003180 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003163 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003592 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002632 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003411 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003397 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003492 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002951 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002875 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003026 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002556 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003032 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003474 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002839 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002896 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002997 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003158 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003158 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003486 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003442 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003470 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003151 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003039 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003034 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003340 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003606 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003018 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003417 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003172 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003666 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002994 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003243 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003013 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003095 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003168 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003116 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003221 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003406 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.563327\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003607 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 649\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4896.355414\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003209 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180730, number of used features: 9\n","[LightGBM] [Info] Start training from score 4907.327489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003249 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4892.040065\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003343 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 650\n","[LightGBM] [Info] Number of data points in the train set: 180731, number of used features: 9\n","[LightGBM] [Info] Start training from score 4899.657823\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004484 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 225913, number of used features: 9\n","[LightGBM] [Info] Start training from score 4897.588820\n"]},{"data":{"text/plain":["1729.519953992008"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["boosting = MultiModelLearning('boosting')\n","boosting.fit(X_train_ridge_oe, y_train)\n","boosting.best_score"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004082 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 652\n","[LightGBM] [Info] Number of data points in the train set: 225913, number of used features: 9\n","[LightGBM] [Info] Start training from score 4897.588820\n","CPU times: total: 2.11 s\n","Wall time: 389 ms\n"]}],"source":["%%time\n","boosting.new_learn()"]},{"cell_type":"markdown","metadata":{},"source":["### Вывод по разделу"]},{"cell_type":"markdown","metadata":{},"source":["* Модели удовлетворяющие условиям заказчика: бустинг, бэггинг и дерево решений со значениями RMSE 1729, 1706 и 1914 соответственно.\n","* Время обучения бэггинга - 3 секунды, дерева решений - 0.4 секунды, бустинга - 0.4 секунды."]},{"cell_type":"markdown","metadata":{},"source":["\n","<div class=\"alert alert-block alert-danger\">\n","<b>Ошибка:</b> Не увидел замера времени обучения.\n","    \n","- время обучения это  чистый `.fit()` модели - без подбора гиперпараметров и без предсказаний,  то есть время обучения gridsearch не подойдет\n","    \n","\n","p.s. можно вытаскивать  все  метрики  интересующие заказчика лаконично из GridSearchCV/RandomizedSearchCV, все они лежат в `.cv_results_`\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["## Анализ качества моделей"]},{"cell_type":"markdown","metadata":{},"source":["### Скорость работы моделей"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 1.16 s\n","Wall time: 193 ms\n"]},{"data":{"text/plain":["array([4522.22647164, 5982.17253131, 5486.00975121, ..., 9466.23305321,\n","       5179.2666109 , 6171.6830594 ])"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","boosting.predict(X_train_ridge_oe)"]},{"cell_type":"code","execution_count":52,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 922 ms\n","Wall time: 518 ms\n"]},{"data":{"text/plain":["array([4172.59174159, 5740.66354952, 4809.42857143, ..., 9113.77800454,\n","       5149.92653061, 7071.98571429])"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","bagging.predict(X_train_ridge_oe)"]},{"cell_type":"code","execution_count":53,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 31.2 ms\n","Wall time: 33.5 ms\n"]},{"data":{"text/plain":["array([3520.25789474, 6141.41269841, 5810.56521739, ..., 9673.83870968,\n","       5306.1146789 , 6673.29816514])"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","tree.predict(X_train_ridge_oe)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Изменения:</b> добавил табличку с результатами моделей\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["Бэггинг формирует предсказание 0.5 секунд, решающее деверо - 0.03 секунды, бустинг - 0.18 секунд."]},{"cell_type":"markdown","metadata":{},"source":["<table>\n","    <tr>\n","        <td></td>\n","        <td>Скорость обучения</td>\n","        <td>Значение RMSE</td>\n","        <td>Скорость работы</td>\n","    </tr>\n","    <tr>\n","        <td>Решающее дерево</td>\n","        <td>0.4 c</td>\n","        <td>1914</td>\n","        <td>0.03 c</td>\n","    </tr>\n","    <tr>\n","        <td>Бэггинг</td>\n","        <td>3 c</td>\n","        <td>1706</td>\n","        <td>0.5 c</td>\n","    </tr>\n","    <tr>\n","        <td>LightGBM</td>\n","        <td>0.4 c</td>\n","        <td>1729</td>\n","        <td>0.18 c</td>\n","    </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{},"source":["Таким образом бустинг уступает в скорости предсказаний решающему дереву, но имеет более высокую точность."]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    \n","<b>Совет:</b> Неплохо было бы собрать все результаты в информативную таблицу\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Проверка лучшей модели на тестовой выборке"]},{"cell_type":"code","execution_count":54,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["1798.1475647401621"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["boost_predict = boosting.predict(X_test_ridge_oe)\n","root_mean_squared_error(y_test, boost_predict)"]},{"cell_type":"markdown","metadata":{},"source":["### Проверка модели на адекватность"]},{"cell_type":"code","execution_count":55,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["4574.064358069068"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["dummy = MultiModelLearning('dummy')\n","dummy.fit(X_test_ridge_oe, y_test)\n","dummy.best_score"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Изменения:</b> добавил график с важностью каждого параметра.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["### Важность параметров в итоговой модели"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["importances = boosting.best_model.feature_importances_\n","forest_importances = pd.Series(importances, index=features.columns)\n","\n","fig, ax = plt.subplots()\n","forest_importances.plot.bar(ax=ax)\n","ax.set_title(\"Feature importances using MDI\")\n","ax.set_ylabel(\"Mean decrease in impurity\")\n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{},"source":["### Выводы по качеству моделей и выбор лучшей"]},{"cell_type":"markdown","metadata":{},"source":["* Под критерий \"Значение метрики RMSE должно быть меньше 2500\" подходят модил бустинга, бэггинга и решающего дерева со значениями RMSE 1729, 1706 и 1914 соответственно.\n","* Время обучения бэггинга - 3 секунды, дерева решений - 0.4 секунды, бустинга 0.4 секунды.\n","* Бэггинг формирует предсказание 0.5 секунд, решающее деверо - 0.03 секунды, бустинг - 0.18 секунд.\n","* Так как заказчику важно и значение метрики RMSE, и время обучения модели, и время ее работы лучшая модель из обученных - бустинг. Эта модель быстрее всего учится и работает и при этом имеет приемлимое значение метрики RMSE.\n","* Значение RMSE бустинга также меньше 2500 на тестовых данных."]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","<b>Совет:</b> \n","\n","Также если говорить, что можно ещё улучшить в подобных проектах, то я бы выделил такие моменты:<br>\n","    \n","1) напомню, что для понимания, а какие в итоге факторы важны при моделировании, можно выводить их важность, использую feature_importances_, ну и график заодно. \n","    \n","2) У нас разный возраст машин. Есть гипотеза, что для разных возрастов - своё ценообразование. Поэтому, можно попробовать ввести фактор \"тип возраста\" (ретро, супер-ретро, старая, новая... надо подумать..)..<br>\n","\n","3) У некоторых моделей семейства бустингов, есть внутренний метод кодировки данных, который хорошо было бы попробовать\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Общий вывод"]},{"cell_type":"markdown","metadata":{},"source":["* Предобработка и анализ данных: \n","\n","    * Удалены ненужные колонки.\n","    * Удалены аномалии в количественных признаках.\n","    * Пропуски в колонках (vehicle_type, model, fuel_type) заполнены заглушкой unknown, а в колонках gearbox и repaired предыдущим значение.\n","    * Найдены дубликаты, однако было решено их оставить. \n","    * Категориальные признаки были преобразованы в численные методом прямого кодирования для обучения моделей.\n","    * Выборка была разбита на обучающую и тестовую.\n","    \n","* Обучение моделей:\n","\n","    * Были обучены модели: решающего дерева, линейной регрессии, бэггинга и бустинга.\n","    * Под критерий \"Значение метрики RMSE должно быть меньше 2500\" подходят модели бустинга, бэггинга и решающего дерева со значениями RMSE 1729, 1706 и 1914 соответственно.\n","    Время обучения бэггинга - 3 секунды, дерева решений - 0.4 секунды, бустинга 0.4 секунды.\n","    * Бэггинг формирует предсказание 0.5 секунд, решающее деверо - 0.03 секунды, бустинг - 0.18 секунд.\n","    * Так как заказчику важно и значение метрики RMSE, и время обучения модели, и время ее работы лучшая модель из обученных - бустинг. Эта модель быстрее всего учится и работает и при этом имеет приемлимое значение метрики RMSE.\n","    * Значение RMSE бустинга также меньше 2500 на тестовых данных.\n","\n","* Общий итог:\n","\n","    * На основе полученных данных была создана модель, предсказывающая цену на автомобиль по вводимым пользователем признакам с погрешностью меньше 2500. \n","    * Время обучения этой модели составило 0.4 секунды а скорость работы 0.2 секунды.\n","    * Также стоит обратить внимание а остельные две модели удовлетворяющие условию (RMSE < 2500): бэггинг более точно предсказывает, а решающее дерево быстрее работает."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":2}
